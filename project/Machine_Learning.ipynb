{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_neighborhood.pkl', 'rb') as handle:\n",
    "    df_neigh = pickle.load(handle)\n",
    "with open('df_target.pkl', 'rb') as handle:\n",
    "    df_target = pickle.load(handle)\n",
    "df_neigh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_neigh['nb_taxi_scale'] = scaler.fit_transform(df_neigh[['nb_taxi_km']])\n",
    "df_neigh['nb_transp_scale'] = scaler.fit_transform(df_neigh[['nb_transp_km']])\n",
    "df_neigh['nb_rest_scale'] = scaler.fit_transform(df_neigh[['nb_rest_km']])\n",
    "df_neigh['nb_shop_scale'] = scaler.fit_transform(df_neigh[['nb_shop_km']])\n",
    "df_neigh['nb_entertainement_scale'] = scaler.fit_transform(df_neigh[['nb_entertainement_km']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = df_neigh['noise_cat']\n",
    "y_noise = pd.DataFrame.copy(noise)\n",
    "\n",
    "clean = df_neigh['clean_cat']\n",
    "y_clean = pd.DataFrame.copy(clean)\n",
    "\n",
    "smell = df_neigh['smell_cat']\n",
    "y_smell = pd.DataFrame.copy(smell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate DF data and ML data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_neigh[['nb_taxi_scale','nb_transp_scale','nb_rest_scale','nb_shop_scale','nb_entertainement_scale']]\n",
    "data_no_taxi = df_neigh[['nb_transp_scale','nb_rest_scale','nb_shop_scale','nb_entertainement_scale']]\n",
    "data_no_rest = df_neigh[['nb_taxi_scale','nb_transp_scale','nb_shop_scale','nb_entertainement_scale']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) For noise / smell / clean predictions using Random Forest --- All data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find the best parameters for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for noise: {'max_depth': 1, 'n_estimators': 1}\n",
      "Best parameters for smell: {'max_depth': 1, 'n_estimators': 1}\n",
      "Best parameters for clean: {'max_depth': 1, 'n_estimators': 7}\n"
     ]
    }
   ],
   "source": [
    "#### NOISE\n",
    "param_grid = {'max_depth': [1, 3, 5, 7], 'n_estimators' : [1, 3, 5, 7]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data, y_noise)\n",
    "# Print the best parameters\n",
    "print(\"Best parameters for noise: \" + str(search.best_params_))\n",
    "\n",
    "#### SMELL\n",
    "param_grid = {'max_depth': [1, 3, 5, 7], 'n_estimators' : [1, 3, 5, 7]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data, y_smell)\n",
    "print(\"Best parameters for smell: \" + str(search.best_params_))\n",
    "\n",
    "#### CLEAN\n",
    "param_grid = {'max_depth': [1, 3, 5, 7], 'n_estimators' : [1, 3, 5, 7]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data, y_clean)\n",
    "print(\"Best parameters for clean: \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Test with the real Model using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of noise prediction: 0.8307692307692308\n",
      "Score of smell prediction: 0.9692307692307693\n",
      "Score of clean prediction: 0.6153846153846153\n"
     ]
    }
   ],
   "source": [
    "#### NOISE\n",
    "rfc = RandomForestClassifier(max_depth=1, n_estimators=1)\n",
    "# use cross validation\n",
    "scores = cross_val_score(rfc, data, y_noise, cv=ShuffleSplit(n_splits=5))\n",
    "# print score\n",
    "print(\"Score of noise prediction: \" + str(np.mean(scores)))\n",
    "\n",
    "#### SMELL\n",
    "rfc = RandomForestClassifier(max_depth=1, n_estimators=1)\n",
    "scores = cross_val_score(rfc, data, y_smell, cv=ShuffleSplit(n_splits=5))\n",
    "print(\"Score of smell prediction: \" + str(np.mean(scores)))\n",
    "\n",
    "#### CLEAN\n",
    "rfc = RandomForestClassifier(max_depth=1, n_estimators=7)\n",
    "scores = cross_val_score(rfc, data, y_clean, cv=ShuffleSplit(n_splits=5))\n",
    "print(\"Score of clean prediction: \" + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation on the results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Noise and smell predictions are very accurate (more than 83% of success) processed by cross validation.\n",
    "Clean predictions are more accurate than random classification. However we need to look closer to see how can we improve this prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) For noise / smell / clean predictions using Random Forest --- Without taxi data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find the best parameters for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for noise: {'max_depth': 5, 'n_estimators': 7}\n",
      "Best parameters for smell: {'max_depth': 1, 'n_estimators': 1}\n",
      "Best parameters for clean: {'max_depth': 1, 'n_estimators': 3}\n"
     ]
    }
   ],
   "source": [
    "#### NOISE\n",
    "param_grid = {'max_depth': [1, 3, 5, 7], 'n_estimators' : [1, 3, 5, 7]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data_no_taxi, y_noise)\n",
    "# Print the best parameters\n",
    "print(\"Best parameters for noise: \" + str(search.best_params_))\n",
    "\n",
    "#### SMELL\n",
    "param_grid = {'max_depth': [1, 3, 5, 7], 'n_estimators' : [1, 3, 5, 7]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data_no_taxi, y_smell)\n",
    "print(\"Best parameters for smell: \" + str(search.best_params_))\n",
    "\n",
    "#### CLEAN\n",
    "param_grid = {'max_depth': [1, 3, 5, 7], 'n_estimators' : [1, 3, 5, 7]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data_no_taxi, y_clean)\n",
    "print(\"Best parameters for clean: \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Test with the real Model using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of noise prediction: 0.7692307692307692\n",
      "Score of smell prediction: 0.9846153846153847\n",
      "Score of clean prediction: 0.6\n"
     ]
    }
   ],
   "source": [
    "#### NOISE\n",
    "rfc = RandomForestClassifier(max_depth=5, n_estimators=7)\n",
    "# use cross validation\n",
    "scores = cross_val_score(rfc, data_no_taxi, y_noise, cv=ShuffleSplit(n_splits=5))\n",
    "# print score\n",
    "print(\"Score of noise prediction: \" + str(np.mean(scores)))\n",
    "\n",
    "#### SMELL\n",
    "rfc = RandomForestClassifier(max_depth=1, n_estimators=1)\n",
    "scores = cross_val_score(rfc, data_no_taxi, y_smell, cv=ShuffleSplit(n_splits=5))\n",
    "print(\"Score of smell prediction: \" + str(np.mean(scores)))\n",
    "\n",
    "#### CLEAN\n",
    "rfc = RandomForestClassifier(max_depth=1, n_estimators=3)\n",
    "scores = cross_val_score(rfc, data_no_taxi, y_clean, cv=ShuffleSplit(n_splits=5))\n",
    "print(\"Score of clean prediction: \" + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation on the results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Noise\n",
    "Before 0.8307692307692308 - After 0.7692307692307692 --> 0.06153846153846165 (6.1%)\n",
    "# Smell\n",
    "Before 0.9692307692307693 - After 0.9846153846153847 --> 0.01538461538461533 (1.5%)\n",
    "# Clean\n",
    "Before 0.6153846153846153 - After 0.6                --> 0.01538461538461533 (1.5%)\n",
    "\n",
    "Overview : taxis have an impact on the 3 targets but 2 targets (smell and clean) are just a little affected (1.5%) whereas the taxis have a big impact on the noise (6.1% impact on noise between presence of taxis or not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) For noise / smell / clean predictions using Random Forest --- Without restaurant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find the best parameters for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for noise: {'max_depth': 7, 'n_estimators': 5}\n",
      "Best parameters for smell: {'max_depth': 1, 'n_estimators': 1}\n",
      "Best parameters for clean: {'max_depth': 1, 'n_estimators': 3}\n"
     ]
    }
   ],
   "source": [
    "#### NOISE\n",
    "param_grid = {'max_depth': [1, 3, 5, 7], 'n_estimators' : [1, 3, 5, 7]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data_no_rest, y_noise)\n",
    "# Print the best parameters\n",
    "print(\"Best parameters for noise: \" + str(search.best_params_))\n",
    "\n",
    "#### SMELL\n",
    "param_grid = {'max_depth': [1, 3, 5, 7], 'n_estimators' : [1, 3, 5, 7]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data_no_rest, y_smell)\n",
    "print(\"Best parameters for smell: \" + str(search.best_params_))\n",
    "\n",
    "#### CLEAN\n",
    "param_grid = {'max_depth': [1, 3, 5, 7], 'n_estimators' : [1, 3, 5, 7]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data_no_rest, y_clean)\n",
    "print(\"Best parameters for clean: \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Test with the real Model using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of noise prediction: 0.6461538461538462\n",
      "Score of smell prediction: 0.9692307692307693\n",
      "Score of clean prediction: 0.5230769230769231\n"
     ]
    }
   ],
   "source": [
    "#### NOISE\n",
    "rfc = RandomForestClassifier(max_depth=7, n_estimators=5)\n",
    "# use cross validation\n",
    "scores = cross_val_score(rfc, data_no_rest, y_noise, cv=ShuffleSplit(n_splits=5))\n",
    "# print score\n",
    "print(\"Score of noise prediction: \" + str(np.mean(scores)))\n",
    "\n",
    "#### SMELL\n",
    "rfc = RandomForestClassifier(max_depth=1, n_estimators=1)\n",
    "scores = cross_val_score(rfc, data_no_rest, y_smell, cv=ShuffleSplit(n_splits=5))\n",
    "print(\"Score of smell prediction: \" + str(np.mean(scores)))\n",
    "\n",
    "#### CLEAN\n",
    "rfc = RandomForestClassifier(max_depth=1, n_estimators=3)\n",
    "scores = cross_val_score(rfc, data_no_rest, y_clean, cv=ShuffleSplit(n_splits=5))\n",
    "print(\"Score of clean prediction: \" + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation on the results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Noise\n",
    "Before 0.8307692307692308 - After 0.6461538461538462 --> 0.18461538461538463 (18.4%)\n",
    "# Smell\n",
    "Before 0.9692307692307693 - After 0.9692307692307693 --> 0 (0%)\n",
    "# Clean\n",
    "Before 0.6153846153846153 - After 0.5230769230769231 --> 0.0923076923076922 (9.2%)\n",
    "\n",
    "Overview : restaurants have a big impact on noiseness and cleanness while the smell is not affected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) For noise / smell / clean predictions using Support Vector Machine (SVM) --- All data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find the best parameters for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOISE\n",
    "param_grid = {}\n",
    "search = GridSearchCV(SVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data, y_noise)\n",
    "# Print the best estimated parameters\n",
    "print(\"Best parameters for noise: \" + str(search.best_estimator_))\n",
    "\n",
    "#### SMELL\n",
    "search = GridSearchCV(SVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data, y_smell)\n",
    "print(\"Best parameters for smell: \" + str(search.best_estimator_))\n",
    "\n",
    "#### CLEAN\n",
    "search = GridSearchCV(SVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data, y_clean)\n",
    "print(\"Best parameters for clean: \" + str(search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Test with the real Model using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of noise prediction: 0.7384615384615385\n",
      "Score of smell prediction: 0.9538461538461538\n",
      "Score of clean prediction: 0.5692307692307692\n"
     ]
    }
   ],
   "source": [
    "#### NOISE\n",
    "svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "# use cross validation\n",
    "scores = cross_val_score(svc, data, y_noise, cv=ShuffleSplit(n_splits=5))\n",
    "# print score\n",
    "print(\"Score of noise prediction: \" + str(np.mean(scores)))\n",
    "\n",
    "#### SMELL\n",
    "svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "scores = cross_val_score(svc, data, y_smell, cv=ShuffleSplit(n_splits=5))\n",
    "print(\"Score of smell prediction: \" + str(np.mean(scores)))\n",
    "\n",
    "#### CLEAN\n",
    "svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "scores = cross_val_score(svc, data, y_clean, cv=ShuffleSplit(n_splits=5))\n",
    "print(\"Score of clean prediction: \" + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation on the results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Noise and smell predictions are very accurate (more than 73% of success) processed by cross validation.\n",
    "Clean predictions are more accurate than random classification. However we need to look closer to see how can we improve this prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) For noise / smell / clean predictions using Support Vector Machine (SVM) --- No taxi data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find the best parameters for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOISE\n",
    "param_grid = {}\n",
    "search = GridSearchCV(SVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data_no_taxi, y_noise)\n",
    "# Print the best estimated parameters\n",
    "print(\"Best parameters for noise: \" + str(search.best_estimator_))\n",
    "\n",
    "#### SMELL\n",
    "search = GridSearchCV(SVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data_no_taxi, y_smell)\n",
    "print(\"Best parameters for smell: \" + str(search.best_estimator_))\n",
    "\n",
    "#### CLEAN\n",
    "search = GridSearchCV(SVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data_no_taxi, y_clean)\n",
    "print(\"Best parameters for clean: \" + str(search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Test with the real Model using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of noise prediction: 0.8\n",
      "Score of smell prediction: 0.9230769230769231\n",
      "Score of clean prediction: 0.7076923076923077\n"
     ]
    }
   ],
   "source": [
    "#### NOISE\n",
    "svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "# use cross validation\n",
    "scores = cross_val_score(svc, data_no_taxi, y_noise, cv=ShuffleSplit(n_splits=5))\n",
    "# print score\n",
    "print(\"Score of noise prediction: \" + str(np.mean(scores)))\n",
    "\n",
    "#### SMELL\n",
    "svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "scores = cross_val_score(svc, data_no_taxi, y_smell, cv=ShuffleSplit(n_splits=5))\n",
    "print(\"Score of smell prediction: \" + str(np.mean(scores)))\n",
    "\n",
    "#### CLEAN\n",
    "svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "scores = cross_val_score(svc, data_no_taxi, y_clean, cv=ShuffleSplit(n_splits=5))\n",
    "print(\"Score of clean prediction: \" + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation on the results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Noise\n",
    "Before 0.7384615384615385 - After 0.8                --> 0.06153846153846154 (6.1%)\n",
    "# Smell\n",
    "Before 0.9538461538461538 - After 0.9230769230769231 --> 0.03076923076923066 (3%)\n",
    "# Clean\n",
    "Before 0.5692307692307692 - After 0.7076923076923077 --> 0.13846153846153852 (13.8%)\n",
    "\n",
    "Overview : According to the model, taxis have a big impact on noise and clean (6.1% & 13.8%) while the taxi smell would be affected by only 3% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) For noise / smell / clean predictions using Support Vector Machine (SVM) --- No restaurant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find the best parameters for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOISE\n",
    "param_grid = {}\n",
    "search = GridSearchCV(SVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data_no_rest, y_noise)\n",
    "# Print the best estimated parameters\n",
    "print(\"Best parameters for noise: \" + str(search.best_estimator_))\n",
    "\n",
    "#### SMELL\n",
    "search = GridSearchCV(SVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data_no_rest, y_smell)\n",
    "print(\"Best parameters for smell: \" + str(search.best_estimator_))\n",
    "\n",
    "#### CLEAN\n",
    "search = GridSearchCV(SVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(data_no_rest, y_clean)\n",
    "print(\"Best parameters for clean: \" + str(search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Test with the real Model using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of noise prediction: 0.6923076923076923\n",
      "Score of smell prediction: 0.9538461538461538\n",
      "Score of clean prediction: 0.5692307692307693\n"
     ]
    }
   ],
   "source": [
    "#### NOISE\n",
    "svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "# use cross validation\n",
    "scores = cross_val_score(svc, data_no_rest, y_noise, cv=ShuffleSplit(n_splits=5))\n",
    "# print score\n",
    "print(\"Score of noise prediction: \" + str(np.mean(scores)))\n",
    "\n",
    "#### SMELL\n",
    "svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "scores = cross_val_score(svc, data_no_rest, y_smell, cv=ShuffleSplit(n_splits=5))\n",
    "print(\"Score of smell prediction: \" + str(np.mean(scores)))\n",
    "\n",
    "#### CLEAN\n",
    "svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "scores = cross_val_score(svc, data_no_rest, y_clean, cv=ShuffleSplit(n_splits=5))\n",
    "print(\"Score of clean prediction: \" + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation on the results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Noise\n",
    "Before 0.7384615384615385 - After 0.6923076923076923 --> 0.04615384615384621 (4.6%)\n",
    "# Smell\n",
    "Before 0.9538461538461538 - After 0.9538461538461538 --> 0.03076923076923066 (3%)\n",
    "# Clean\n",
    "Before 0.5692307692307692 - After 0.5692307692307693 --> 1.1102230246251565e-16 (<0.1%)\n",
    "\n",
    "Overview : According to the model, restaurants have slightly impacted the noiseness and the smellness but not the cleanness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- DataFrame used for the prediction : \"df_neighborhood.pkl\" \n",
    "\n",
    "- Cendus POI : \n",
    "\n",
    "        [Shopping subcategories]\n",
    "        shop_subcat = ['Vehicle Sales Shop', 'Supermarket Convenience Store', 'Market', 'Home Building Materials Retail Shop',\n",
    "                    'Clothing, shoes and leather retail store', 'Food-beverage and tobacco products retail stores', \n",
    "                    'Integrated market', 'Characteristic Commercial Street', 'Flower, Bird, Insect and Fish Market']\n",
    "                    \n",
    "        [Entertainement categories & subcategories]\n",
    "        entert_cat = ['Stadium and Gymnasium', 'Movie theater', 'Sports and leisure']        \n",
    "        entert_subcat = ['Song and dance hall/nightclub', 'Game Hall/Video City', 'Entertainment place', 'KTV', 'Bar']\n",
    "                    \n",
    "        [All restaurants]\n",
    "        [All transports]\n",
    "\n",
    "- Taxis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the folder you can find 3 pickles:\n",
    " - model of NOISE target --> noise_model.pkl\n",
    " - model of CLEAN target --> clean_model.pkl\n",
    " - model of SMELL target --> smell_model.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Description of the different notebooks:\n",
    " - Data_Collection: contains all the data selection & cleaning & gathering from the different datasets\n",
    " - Machine_Learning: contains all the Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISCUSSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation of the choices"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I) I based the wellbeing prediction on the neighborhood 3 targets : Clean, Noise and Smell\n",
    "A wellbeing score based on those targets is a very subjective question : is smellness a more important target than cleanness ? What about noiseness ? \n",
    "To avoid these question I made the following steps: I choosed to predict the targets one by one instead of making a global category so that I could be focused more on the question \"what affect which target\" instead of being focused on \"what affect the global wellbeing\".\n",
    "\n",
    "II) After seeing some data graphs, I decided to take several datasets that has a big impact on at least one of the targets. The datasets used you can find : Taxis, Transports, Restaurants, Shops, Entertainements in Shanghai.\n",
    "\n",
    "III) The targets are numbers and are transformed into classes for more readability. The predictions are then classes and not numbers. The predictions are made with a Machine Learning Classification algorithm. As I don't have that much data to process I was focused on accurate algorithms (instead of quick algorithms): Random Forest and Support Vector Machine classifiers.\n",
    "Because of my lack of data (only 120 input rows), I decided to use cross validation so that all the data will be splitted and took part of both training and testing parts.\n",
    "\n",
    "IV) I wanted to assess more datasets into ML (find correlation with transportation dataset for example) but need too much time to set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Understanding of the prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Above, at the bottom of each model and prediction you can find some basic analysis\n",
    "\n",
    "All predictions for NOISE and SMELL targets (2 categories) are always more (more more) accurate than random classification (more than 50%)\n",
    "All predictions for CLEAN targets (4 categories) are always more accurate than random classification (more than 25%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recommandation for Shanghai city"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Following the analysis I can conclude that:\n",
    "    Improve the smellness:\n",
    "        - Reduce the number of restaurants\n",
    "    Improve the noiseness:\n",
    "        - Reduce the number of restaurants\n",
    "        - Reduce the number of taxis\n",
    "    Improve the cleanness:\n",
    "        - Reduce the number of taxis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
